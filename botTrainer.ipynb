{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebswU/cf-python/blob/master/botTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlKMGWJ0FafQ"
      },
      "source": [
        "# This is the playground section for different models and datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2oCeu8XxFYw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YweSL-kgPP1"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "import urllib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VagosqN1E4PI"
      },
      "source": [
        "preprocess, getting and dividing data, naming classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSZtC4D6D7MP",
        "outputId": "4bec0fc4-ed5e-409e-ce3d-d489c91ccf00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "fashion = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_train_test, y_train_test) = fashion.load_data()\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "#make it to be between 0-1 not 0-255\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "class_names[y_train[0]]\n",
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTsj7z9FE0dO"
      },
      "source": [
        "Practice sequential model design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm_0BA8pL5Xg",
        "outputId": "d8a9b235-1855-43fc-8648-0658674052c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 16s 8ms/step - loss: 0.6980 - accuracy: 0.7713 - val_loss: 0.4954 - val_accuracy: 0.8332\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4835 - accuracy: 0.8314 - val_loss: 0.4307 - val_accuracy: 0.8556\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4392 - accuracy: 0.8465 - val_loss: 0.4268 - val_accuracy: 0.8498\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4126 - accuracy: 0.8555 - val_loss: 0.3904 - val_accuracy: 0.8668\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3926 - accuracy: 0.8620 - val_loss: 0.3964 - val_accuracy: 0.8632\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3765 - accuracy: 0.8672 - val_loss: 0.3903 - val_accuracy: 0.8596\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3635 - accuracy: 0.8708 - val_loss: 0.3725 - val_accuracy: 0.8698\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3517 - accuracy: 0.8753 - val_loss: 0.3498 - val_accuracy: 0.8786\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3418 - accuracy: 0.8788 - val_loss: 0.3450 - val_accuracy: 0.8806\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3330 - accuracy: 0.8815 - val_loss: 0.3391 - val_accuracy: 0.8802\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape = [28,28]),\n",
        "    keras.layers.Dense(300, activation = 'relu'),\n",
        "    keras.layers.Dense(100, activation = 'relu'),\n",
        "    keras.layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
        "              optimizer = \"sgd\",\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs = 10, validation_data = (X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRCEOHLNQCzt"
      },
      "outputs": [],
      "source": [
        "import sklearn as sk\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test,y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.fit(X_valid)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbvarmhTEwz3"
      },
      "source": [
        "Install tensorflow text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eAPoswVn4_EP",
        "outputId": "b45f176e-d6df-4a80-cff1-62cab5460525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.14.0)\n",
            "Collecting tensorflow<2.14,>=2.13.0 (from tensorflow-text)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<2.14,>=2.13.0->tensorflow-text)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow<2.14,>=2.13.0->tensorflow-text)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<2.14,>=2.13.0->tensorflow-text)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<2.14,>=2.13.0->tensorflow-text)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-text-2.13.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install tensorflow-text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoAgH1UYEqK4"
      },
      "source": [
        "Experimentation with potential model design for Covifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB-Gq2nEy4o4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e313c3c9-5726-4b5c-cf64-aa15be77999a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0344f2a85988>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_module_for_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_embedding_column_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLatestModuleExporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \"\"\"Regularly exports registered modules into timestamped directories.\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/_api/v1/estimator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselineClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaselineEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/_api/v1/estimator/tpu/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_estimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEstimatorSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_wrapper\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mref_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/ref_variable.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m ops.register_proto_function(\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mproto_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariableDef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mregister_proto_function\u001b[0;34m(collection_name, proto_type, to_proto, from_proto)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/registry.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, candidate, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LOCATION_TAG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       raise KeyError(\n\u001b[0m\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"Registering two %s with name '%s'! \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0;34m\"(Previous registration was in %s %s:%d)\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Registering two proto functions with name 'variables'! (Previous registration was in register /usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/registry.py:65)\""
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as text\n",
        "from tensorflow import keras\n",
        "import json\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmxfu_23XAT5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)#do not fit_transform validation set\n",
        "x_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBVwnmH1dDV0"
      },
      "outputs": [],
      "source": [
        "input_A = keras.layers.Input(shape=[5],name='wide_input')\n",
        "input_B = keras.layers.Input(shape=[6],name='deep_input')\n",
        "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1, name='output')(concat)\n",
        "model = keras.Model(inputs = [input_A, input_B],outputs=[output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE22fRnTJ04l"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation = 'relu'))\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  optimizer = keras.optimizers.SGD(learning_rate = learning_rate)\n",
        "  model.compile(loss = 'mse', optimizer = optimizer)\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI14GRJVWNrv",
        "outputId": "85241ced-5a64-4b2a-c137-4bcb864b6026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-e8b4df3596ed>:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)#can be used on\n"
          ]
        }
      ],
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)#can be used on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G4BXYE8WYSX",
        "outputId": "a44c5498-822a-45b1-ddfb-fd45f5bdeb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "242/242 [==============================] - 5s 7ms/step - loss: 3.1326 - val_loss: 1.7288\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.2528 - val_loss: 1.0123\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9296 - val_loss: 0.8928\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.8309 - val_loss: 0.8396\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.7876 - val_loss: 0.8053\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.7609 - val_loss: 0.7803\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7408 - val_loss: 0.7600\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.7240 - val_loss: 0.7423\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7095 - val_loss: 0.7268\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6959 - val_loss: 0.7127\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6835 - val_loss: 0.6994\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6718 - val_loss: 0.6870\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6603 - val_loss: 0.6750\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6499 - val_loss: 0.6636\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6394 - val_loss: 0.6530\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6295 - val_loss: 0.6429\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6203 - val_loss: 0.6325\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6112 - val_loss: 0.6234\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6025 - val_loss: 0.6144\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5941 - val_loss: 0.6060\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5862 - val_loss: 0.5970\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5784 - val_loss: 0.5889\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5713 - val_loss: 0.5812\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5642 - val_loss: 0.5737\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5575 - val_loss: 0.5662\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5510 - val_loss: 0.5596\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5447 - val_loss: 0.5529\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.5389 - val_loss: 0.5465\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5332 - val_loss: 0.5406\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5278 - val_loss: 0.5353\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.5228 - val_loss: 0.5294\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5180 - val_loss: 0.5246\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5135 - val_loss: 0.5195\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5093 - val_loss: 0.5149\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5052 - val_loss: 0.5108\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5012 - val_loss: 0.5064\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4976 - val_loss: 0.5032\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4943 - val_loss: 0.4987\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4908 - val_loss: 0.4956\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4878 - val_loss: 0.4917\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4845 - val_loss: 0.4885\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4819 - val_loss: 0.4854\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4791 - val_loss: 0.4827\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4766 - val_loss: 0.4798\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4742 - val_loss: 0.4771\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4718 - val_loss: 0.4750\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4696 - val_loss: 0.4721\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4673 - val_loss: 0.4700\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4653 - val_loss: 0.4676\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4633 - val_loss: 0.4652\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4611 - val_loss: 0.4636\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4595 - val_loss: 0.4612\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4574 - val_loss: 0.4592\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4559 - val_loss: 0.4575\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4541 - val_loss: 0.4555\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4525 - val_loss: 0.4537\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4509 - val_loss: 0.4521\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4494 - val_loss: 0.4502\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4478 - val_loss: 0.4488\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4464 - val_loss: 0.4474\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4449 - val_loss: 0.4461\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4434 - val_loss: 0.4455\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 5s 20ms/step - loss: 0.4421 - val_loss: 0.4434\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.4408 - val_loss: 0.4416\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4394 - val_loss: 0.4402\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4382 - val_loss: 0.4393\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 10ms/step - loss: 0.4368 - val_loss: 0.4376\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4358 - val_loss: 0.4364\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4347 - val_loss: 0.4355\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4334 - val_loss: 0.4345\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.4325 - val_loss: 0.4331\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4313 - val_loss: 0.4323\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 0.4302 - val_loss: 0.4311\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4292 - val_loss: 0.4300\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4283 - val_loss: 0.4289\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4273 - val_loss: 0.4283\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4263 - val_loss: 0.4271\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4253 - val_loss: 0.4261\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4244 - val_loss: 0.4255\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4235 - val_loss: 0.4242\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4224 - val_loss: 0.4235\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4217 - val_loss: 0.4227\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4208 - val_loss: 0.4219\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4199 - val_loss: 0.4208\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4190 - val_loss: 0.4203\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4183 - val_loss: 0.4193\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4175 - val_loss: 0.4185\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4167 - val_loss: 0.4182\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4158 - val_loss: 0.4168\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4150 - val_loss: 0.4162\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4143 - val_loss: 0.4152\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4134 - val_loss: 0.4147\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4126 - val_loss: 0.4139\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4119 - val_loss: 0.4128\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4110 - val_loss: 0.4121\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4104 - val_loss: 0.4115\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4096 - val_loss: 0.4108\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4089 - val_loss: 0.4099\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4082 - val_loss: 0.4094\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4075 - val_loss: 0.4089\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4155\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 2.8649 - val_loss: 1.5769\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 3s 12ms/step - loss: 1.2554 - val_loss: 1.0419\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.9164 - val_loss: 0.8687\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.7803 - val_loss: 0.7830\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7152 - val_loss: 0.7349\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6802 - val_loss: 0.7057\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6587 - val_loss: 0.6856\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6435 - val_loss: 0.6699\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6309 - val_loss: 0.6565\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6195 - val_loss: 0.6442\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6094 - val_loss: 0.6336\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5999 - val_loss: 0.6237\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5911 - val_loss: 0.6152\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5832 - val_loss: 0.6054\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5756 - val_loss: 0.5973\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5685 - val_loss: 0.5898\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5617 - val_loss: 0.5826\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5556 - val_loss: 0.5759\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5495 - val_loss: 0.5691\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5440 - val_loss: 0.5630\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5385 - val_loss: 0.5574\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5336 - val_loss: 0.5517\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5285 - val_loss: 0.5464\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5243 - val_loss: 0.5416\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5197 - val_loss: 0.5371\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5157 - val_loss: 0.5324\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5117 - val_loss: 0.5284\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5080 - val_loss: 0.5237\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5045 - val_loss: 0.5199\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5009 - val_loss: 0.5165\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4977 - val_loss: 0.5130\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4942 - val_loss: 0.5090\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4916 - val_loss: 0.5059\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4885 - val_loss: 0.5023\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4860 - val_loss: 0.4992\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4832 - val_loss: 0.4963\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4807 - val_loss: 0.4935\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4782 - val_loss: 0.4908\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4759 - val_loss: 0.4882\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4735 - val_loss: 0.4858\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4715 - val_loss: 0.4832\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4693 - val_loss: 0.4814\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4671 - val_loss: 0.4787\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4653 - val_loss: 0.4766\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4634 - val_loss: 0.4744\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4615 - val_loss: 0.4725\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4597 - val_loss: 0.4707\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4577 - val_loss: 0.4686\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4562 - val_loss: 0.4667\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4546 - val_loss: 0.4649\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4530 - val_loss: 0.4635\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4514 - val_loss: 0.4612\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4499 - val_loss: 0.4602\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4483 - val_loss: 0.4592\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4471 - val_loss: 0.4568\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4455 - val_loss: 0.4553\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4440 - val_loss: 0.4542\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4427 - val_loss: 0.4528\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4415 - val_loss: 0.4509\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4401 - val_loss: 0.4498\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4389 - val_loss: 0.4481\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4376 - val_loss: 0.4469\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4365 - val_loss: 0.4463\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4352 - val_loss: 0.4455\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4342 - val_loss: 0.4434\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4328 - val_loss: 0.4422\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4317 - val_loss: 0.4412\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.4308 - val_loss: 0.4396\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4294 - val_loss: 0.4385\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4284 - val_loss: 0.4376\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4275 - val_loss: 0.4371\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4264 - val_loss: 0.4355\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4254 - val_loss: 0.4344\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4243 - val_loss: 0.4337\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4234 - val_loss: 0.4325\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4223 - val_loss: 0.4316\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4215 - val_loss: 0.4304\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4206 - val_loss: 0.4302\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4197 - val_loss: 0.4291\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4188 - val_loss: 0.4279\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4181 - val_loss: 0.4269\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4170 - val_loss: 0.4259\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4163 - val_loss: 0.4251\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4155 - val_loss: 0.4249\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4147 - val_loss: 0.4233\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4138 - val_loss: 0.4230\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4131 - val_loss: 0.4218\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4123 - val_loss: 0.4219\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4114 - val_loss: 0.4204\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4109 - val_loss: 0.4195\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4102 - val_loss: 0.4188\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4093 - val_loss: 0.4183\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4085 - val_loss: 0.4186\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4079 - val_loss: 0.4169\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4072 - val_loss: 0.4157\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4065 - val_loss: 0.4151\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4060 - val_loss: 0.4144\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4049 - val_loss: 0.4144\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4046 - val_loss: 0.4132\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4038 - val_loss: 0.4127\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4314\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 3s 8ms/step - loss: 3.0508 - val_loss: 1.5825\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 1.2160 - val_loss: 0.9602\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.8722 - val_loss: 0.8210\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7580 - val_loss: 0.7562\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7137 - val_loss: 0.7201\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6878 - val_loss: 0.6953\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6690 - val_loss: 0.6765\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6539 - val_loss: 0.6606\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6408 - val_loss: 0.6470\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6292 - val_loss: 0.6352\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6187 - val_loss: 0.6247\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6092 - val_loss: 0.6152\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.6005 - val_loss: 0.6059\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5922 - val_loss: 0.5974\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5844 - val_loss: 0.5896\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5768 - val_loss: 0.5820\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5702 - val_loss: 0.5748\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5634 - val_loss: 0.5681\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5571 - val_loss: 0.5618\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5510 - val_loss: 0.5556\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5451 - val_loss: 0.5495\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5394 - val_loss: 0.5438\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5342 - val_loss: 0.5383\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5288 - val_loss: 0.5331\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5239 - val_loss: 0.5279\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5190 - val_loss: 0.5230\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5145 - val_loss: 0.5186\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5101 - val_loss: 0.5141\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5058 - val_loss: 0.5098\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5019 - val_loss: 0.5058\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4979 - val_loss: 0.5017\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4943 - val_loss: 0.4978\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4906 - val_loss: 0.4941\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4872 - val_loss: 0.4906\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4839 - val_loss: 0.4872\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4806 - val_loss: 0.4844\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4778 - val_loss: 0.4809\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4748 - val_loss: 0.4778\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4720 - val_loss: 0.4749\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4694 - val_loss: 0.4722\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4666 - val_loss: 0.4700\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4644 - val_loss: 0.4669\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4618 - val_loss: 0.4649\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4597 - val_loss: 0.4621\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4575 - val_loss: 0.4599\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4554 - val_loss: 0.4575\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4534 - val_loss: 0.4556\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4515 - val_loss: 0.4535\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4496 - val_loss: 0.4514\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4478 - val_loss: 0.4498\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4462 - val_loss: 0.4476\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4443 - val_loss: 0.4458\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4429 - val_loss: 0.4440\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4413 - val_loss: 0.4425\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4397 - val_loss: 0.4407\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4384 - val_loss: 0.4391\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4367 - val_loss: 0.4383\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4355 - val_loss: 0.4361\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4340 - val_loss: 0.4348\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4327 - val_loss: 0.4336\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4314 - val_loss: 0.4321\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4302 - val_loss: 0.4307\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4289 - val_loss: 0.4292\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4279 - val_loss: 0.4279\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4267 - val_loss: 0.4267\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4256 - val_loss: 0.4255\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4245 - val_loss: 0.4242\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4233 - val_loss: 0.4231\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4221 - val_loss: 0.4219\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4212 - val_loss: 0.4208\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4198 - val_loss: 0.4203\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4192 - val_loss: 0.4186\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4180 - val_loss: 0.4175\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4171 - val_loss: 0.4165\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4160 - val_loss: 0.4153\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4151 - val_loss: 0.4143\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4135\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4133 - val_loss: 0.4124\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4125 - val_loss: 0.4116\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4116 - val_loss: 0.4107\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4107 - val_loss: 0.4099\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4099 - val_loss: 0.4093\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4092 - val_loss: 0.4080\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4084 - val_loss: 0.4071\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4074 - val_loss: 0.4065\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4068 - val_loss: 0.4056\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4060 - val_loss: 0.4047\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4051 - val_loss: 0.4039\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4043 - val_loss: 0.4030\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4036 - val_loss: 0.4023\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4027 - val_loss: 0.4020\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4021 - val_loss: 0.4011\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4014 - val_loss: 0.3999\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4007 - val_loss: 0.3992\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4000 - val_loss: 0.3984\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3993 - val_loss: 0.3977\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3985 - val_loss: 0.3969\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3978 - val_loss: 0.3966\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3972 - val_loss: 0.3957\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3965 - val_loss: 0.3950\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.4048\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 5ms/step - loss: 1.6127 - val_loss: 0.8934\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.7630 - val_loss: 0.7268\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6678 - val_loss: 0.6633\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6231 - val_loss: 0.6171\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5877 - val_loss: 0.5889\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5607 - val_loss: 0.5581\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5387 - val_loss: 0.5366\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5204 - val_loss: 0.5231\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5070 - val_loss: 0.5068\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4943 - val_loss: 0.4967\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4853 - val_loss: 0.4852\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4769 - val_loss: 0.4761\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4697 - val_loss: 0.4706\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4630 - val_loss: 0.4621\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4573 - val_loss: 0.4572\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4524 - val_loss: 0.4507\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4468 - val_loss: 0.4459\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4431 - val_loss: 0.4424\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4395 - val_loss: 0.4374\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4355 - val_loss: 0.4332\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4320 - val_loss: 0.4290\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4287 - val_loss: 0.4268\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4259 - val_loss: 0.4240\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4231 - val_loss: 0.4222\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4206 - val_loss: 0.4187\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4186 - val_loss: 0.4168\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4161 - val_loss: 0.4131\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4140 - val_loss: 0.4120\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4118 - val_loss: 0.4107\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4106 - val_loss: 0.4063\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4083 - val_loss: 0.4045\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4067 - val_loss: 0.4041\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4049 - val_loss: 0.4018\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4037 - val_loss: 0.4002\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4000\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4005 - val_loss: 0.3992\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.3959\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3975 - val_loss: 0.3970\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3961 - val_loss: 0.3930\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3948 - val_loss: 0.3924\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3936 - val_loss: 0.3922\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3916 - val_loss: 0.3912\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3911 - val_loss: 0.3882\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3898 - val_loss: 0.3908\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3885 - val_loss: 0.3882\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3875 - val_loss: 0.3871\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3869 - val_loss: 0.3854\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3853 - val_loss: 0.3839\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3835 - val_loss: 0.3828\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3825 - val_loss: 0.3842\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3816 - val_loss: 0.3834\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3812 - val_loss: 0.3810\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3798 - val_loss: 0.3799\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3804 - val_loss: 0.3811\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3780 - val_loss: 0.3774\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3765 - val_loss: 0.3778\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3756 - val_loss: 0.3765\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3748 - val_loss: 0.3758\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3731 - val_loss: 0.3744\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3723 - val_loss: 0.3758\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3719 - val_loss: 0.3733\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3708 - val_loss: 0.3729\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 0.3727\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3693 - val_loss: 0.3696\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3679 - val_loss: 0.3700\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3672 - val_loss: 0.3689\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3665 - val_loss: 0.3689\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3668 - val_loss: 0.3679\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3643 - val_loss: 0.3677\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3640 - val_loss: 0.3673\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3628 - val_loss: 0.3683\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3623 - val_loss: 0.3640\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3605 - val_loss: 0.3636\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3606 - val_loss: 0.3636\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3598 - val_loss: 0.3648\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3592 - val_loss: 0.3610\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3583 - val_loss: 0.3633\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3561 - val_loss: 0.3623\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3560 - val_loss: 0.3590\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3553 - val_loss: 0.3605\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3572 - val_loss: 0.3571\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3534 - val_loss: 0.3586\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3533 - val_loss: 0.3570\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3525 - val_loss: 0.3555\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3521 - val_loss: 0.3558\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3505 - val_loss: 0.3550\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3501 - val_loss: 0.3539\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.3482 - val_loss: 0.3565\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 3s 11ms/step - loss: 0.3485 - val_loss: 0.3553\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3487 - val_loss: 0.3522\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3471 - val_loss: 0.3514\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3468 - val_loss: 0.3525\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3480 - val_loss: 0.3524\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3453 - val_loss: 0.3525\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3448 - val_loss: 0.3517\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 3s 10ms/step - loss: 0.3445 - val_loss: 0.3503\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3442 - val_loss: 0.3480\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3425 - val_loss: 0.3488\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3424 - val_loss: 0.3492\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3416 - val_loss: 0.3475\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3561\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 5ms/step - loss: 1.7503 - val_loss: 0.7527\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6631 - val_loss: 0.6424\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6043 - val_loss: 0.6015\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5706 - val_loss: 0.5677\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5490 - val_loss: 0.5444\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5301 - val_loss: 0.5275\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5146 - val_loss: 0.5131\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5026 - val_loss: 0.5026\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4936 - val_loss: 0.4924\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4843 - val_loss: 0.4837\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4764 - val_loss: 0.4767\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4704 - val_loss: 0.4709\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4643 - val_loss: 0.4664\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4597 - val_loss: 0.4617\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4550 - val_loss: 0.4570\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4506 - val_loss: 0.4524\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4470 - val_loss: 0.4485\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4441 - val_loss: 0.4458\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4401 - val_loss: 0.4440\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4378 - val_loss: 0.4411\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4355 - val_loss: 0.4392\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4327 - val_loss: 0.4364\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4307 - val_loss: 0.4355\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4277 - val_loss: 0.4325\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4258 - val_loss: 0.4297\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4241 - val_loss: 0.4285\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4213 - val_loss: 0.4262\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4199 - val_loss: 0.4243\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4168 - val_loss: 0.4230\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4163 - val_loss: 0.4203\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4134 - val_loss: 0.4196\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4119 - val_loss: 0.4172\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4099 - val_loss: 0.4151\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4087 - val_loss: 0.4146\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4078 - val_loss: 0.4122\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4048 - val_loss: 0.4105\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4035 - val_loss: 0.4093\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4019 - val_loss: 0.4094\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4012 - val_loss: 0.4063\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3994 - val_loss: 0.4065\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3973 - val_loss: 0.4051\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3967 - val_loss: 0.4028\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3953 - val_loss: 0.4034\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3936 - val_loss: 0.4021\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3932 - val_loss: 0.4000\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3909 - val_loss: 0.3980\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3897 - val_loss: 0.4014\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3888 - val_loss: 0.3967\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3881 - val_loss: 0.3957\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3865 - val_loss: 0.3950\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3858 - val_loss: 0.3932\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3846 - val_loss: 0.3925\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3832 - val_loss: 0.3922\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3822 - val_loss: 0.3927\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3817 - val_loss: 0.3898\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3800 - val_loss: 0.3903\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3788 - val_loss: 0.3878\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3782 - val_loss: 0.3889\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3771 - val_loss: 0.3870\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3758 - val_loss: 0.3853\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3754 - val_loss: 0.3847\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3742 - val_loss: 0.3823\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3729 - val_loss: 0.3851\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.3817\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3718 - val_loss: 0.3799\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3706 - val_loss: 0.3810\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3696 - val_loss: 0.3791\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3689 - val_loss: 0.3778\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3679 - val_loss: 0.3764\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3666 - val_loss: 0.3762\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3658 - val_loss: 0.3753\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3650 - val_loss: 0.3766\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3641 - val_loss: 0.3729\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3630 - val_loss: 0.3746\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3628 - val_loss: 0.3731\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3615 - val_loss: 0.3702\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3604 - val_loss: 0.3701\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3598 - val_loss: 0.3714\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3588 - val_loss: 0.3688\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3580 - val_loss: 0.3677\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3569 - val_loss: 0.3667\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3564 - val_loss: 0.3682\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3555 - val_loss: 0.3653\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3545 - val_loss: 0.3656\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3529 - val_loss: 0.3660\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3527 - val_loss: 0.3641\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3524 - val_loss: 0.3646\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3517 - val_loss: 0.3615\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3510 - val_loss: 0.3602\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3498 - val_loss: 0.3589\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3491 - val_loss: 0.3584\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3485 - val_loss: 0.3584\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3477 - val_loss: 0.3567\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.3564\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3460 - val_loss: 0.3556\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3450 - val_loss: 0.3550\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3446 - val_loss: 0.3587\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.3437 - val_loss: 0.3596\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.3526\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3423 - val_loss: 0.3519\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3710\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 5ms/step - loss: 1.5162 - val_loss: 0.7830\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.7062 - val_loss: 0.6795\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.6316 - val_loss: 0.6221\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5804 - val_loss: 0.5756\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5460 - val_loss: 0.5488\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5196 - val_loss: 0.5231\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5015 - val_loss: 0.5059\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4855 - val_loss: 0.4887\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4749 - val_loss: 0.4823\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4677 - val_loss: 0.4737\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4629 - val_loss: 0.4638\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4567 - val_loss: 0.4593\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4516 - val_loss: 0.4561\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4514 - val_loss: 0.4538\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4470 - val_loss: 0.4486\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4432 - val_loss: 0.4445\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4400 - val_loss: 0.4406\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4360 - val_loss: 0.4370\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4349 - val_loss: 0.4353\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4326 - val_loss: 0.4344\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4306 - val_loss: 0.4301\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4301 - val_loss: 0.4302\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4271 - val_loss: 0.4262\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4240 - val_loss: 0.4244\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4214 - val_loss: 0.4200\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4197 - val_loss: 0.4196\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4186 - val_loss: 0.4174\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4158 - val_loss: 0.4145\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4145 - val_loss: 0.4133\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4132 - val_loss: 0.4112\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4121 - val_loss: 0.4115\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4114 - val_loss: 0.4100\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.4076 - val_loss: 0.4075\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.4077 - val_loss: 0.4048\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.4039 - val_loss: 0.4057\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4029 - val_loss: 0.4024\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.4018 - val_loss: 0.4012\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.4021 - val_loss: 0.3994\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3994 - val_loss: 0.3965\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3977 - val_loss: 0.3990\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3956 - val_loss: 0.3956\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3949 - val_loss: 0.3932\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3943 - val_loss: 0.3922\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3923 - val_loss: 0.3910\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3913 - val_loss: 0.3901\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3907 - val_loss: 0.3877\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3902 - val_loss: 0.3878\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3912 - val_loss: 0.3860\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3864 - val_loss: 0.3858\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3881 - val_loss: 0.3840\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3829 - val_loss: 0.3830\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3841 - val_loss: 0.3808\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3803 - val_loss: 0.3824\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3811 - val_loss: 0.3792\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3786 - val_loss: 0.3800\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3783 - val_loss: 0.3763\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3761 - val_loss: 0.3782\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3758 - val_loss: 0.3796\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3757 - val_loss: 0.3739\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3755 - val_loss: 0.3732\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3748 - val_loss: 0.3714\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3740 - val_loss: 0.3718\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3756 - val_loss: 0.3701\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3694 - val_loss: 0.3704\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3680 - val_loss: 0.3698\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3663 - val_loss: 0.3679\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3660 - val_loss: 0.3664\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3644 - val_loss: 0.3665\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3640\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3633 - val_loss: 0.3630\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3640 - val_loss: 0.3625\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3622 - val_loss: 0.3620\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3619 - val_loss: 0.3614\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3636 - val_loss: 0.3603\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3585 - val_loss: 0.3603\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3574 - val_loss: 0.3594\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3572 - val_loss: 0.3580\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3557 - val_loss: 0.3568\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3577 - val_loss: 0.3562\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3604 - val_loss: 0.3554\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3537 - val_loss: 0.3554\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3517 - val_loss: 0.3550\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3512 - val_loss: 0.3543\n",
            "Epoch 84/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3512 - val_loss: 0.3520\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3493 - val_loss: 0.3566\n",
            "Epoch 86/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3486 - val_loss: 0.3508\n",
            "Epoch 87/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3479 - val_loss: 0.3496\n",
            "Epoch 88/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3470 - val_loss: 0.3490\n",
            "Epoch 89/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3465 - val_loss: 0.3492\n",
            "Epoch 90/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3465 - val_loss: 0.3494\n",
            "Epoch 91/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3442 - val_loss: 0.3475\n",
            "Epoch 92/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3452 - val_loss: 0.3483\n",
            "Epoch 93/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3429 - val_loss: 0.3494\n",
            "Epoch 94/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.3439 - val_loss: 0.3453\n",
            "Epoch 95/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.3417 - val_loss: 0.3446\n",
            "Epoch 96/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.3410 - val_loss: 0.3449\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.3399 - val_loss: 0.3433\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.3405 - val_loss: 0.3423\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3402 - val_loss: 0.3444\n",
            "Epoch 100/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.3385 - val_loss: 0.3412\n",
            "121/121 [==============================] - 0s 2ms/step - loss: 0.3579\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 3.9270 - val_loss: 2.4409\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.7996 - val_loss: 1.2916\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 1.0331 - val_loss: 0.8440\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.7412 - val_loss: 0.6650\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6262 - val_loss: 0.5927\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5801 - val_loss: 0.5624\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5605 - val_loss: 0.5486\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5517 - val_loss: 0.5422\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5473 - val_loss: 0.5388\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5448 - val_loss: 0.5366\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5430 - val_loss: 0.5347\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5416 - val_loss: 0.5333\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5403 - val_loss: 0.5321\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5392 - val_loss: 0.5311\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5381 - val_loss: 0.5303\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5371 - val_loss: 0.5288\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5362 - val_loss: 0.5282\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5354 - val_loss: 0.5274\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5345 - val_loss: 0.5265\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5338 - val_loss: 0.5260\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5331 - val_loss: 0.5250\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5325 - val_loss: 0.5242\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5318 - val_loss: 0.5234\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5313 - val_loss: 0.5231\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5308 - val_loss: 0.5223\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5304 - val_loss: 0.5218\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5298 - val_loss: 0.5218\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5293 - val_loss: 0.5210\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5290 - val_loss: 0.5210\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5287 - val_loss: 0.5206\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5282 - val_loss: 0.5198\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5279 - val_loss: 0.5191\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5276 - val_loss: 0.5186\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5274 - val_loss: 0.5191\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5270 - val_loss: 0.5184\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5267 - val_loss: 0.5177\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5267 - val_loss: 0.5179\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5263 - val_loss: 0.5175\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5261 - val_loss: 0.5170\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5260 - val_loss: 0.5177\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5258 - val_loss: 0.5178\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5256 - val_loss: 0.5171\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5255 - val_loss: 0.5167\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5253 - val_loss: 0.5171\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5251 - val_loss: 0.5162\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5250 - val_loss: 0.5158\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5250 - val_loss: 0.5161\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5248 - val_loss: 0.5158\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5247 - val_loss: 0.5153\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5247 - val_loss: 0.5157\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5244 - val_loss: 0.5152\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5243 - val_loss: 0.5148\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5244 - val_loss: 0.5156\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5243 - val_loss: 0.5157\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5242 - val_loss: 0.5158\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5239 - val_loss: 0.5147\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5239 - val_loss: 0.5143\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5241 - val_loss: 0.5146\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5239 - val_loss: 0.5152\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5238 - val_loss: 0.5145\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5237 - val_loss: 0.5142\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5238 - val_loss: 0.5150\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5238 - val_loss: 0.5149\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5235 - val_loss: 0.5142\n",
            "Epoch 65/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5237 - val_loss: 0.5149\n",
            "Epoch 66/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5236 - val_loss: 0.5146\n",
            "Epoch 67/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.5236 - val_loss: 0.5145\n",
            "Epoch 68/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5236 - val_loss: 0.5149\n",
            "Epoch 69/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5235 - val_loss: 0.5143\n",
            "Epoch 70/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5234 - val_loss: 0.5136\n",
            "Epoch 71/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5235 - val_loss: 0.5139\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5233 - val_loss: 0.5133\n",
            "Epoch 73/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5234 - val_loss: 0.5132\n",
            "Epoch 74/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5235 - val_loss: 0.5135\n",
            "Epoch 75/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5234 - val_loss: 0.5136\n",
            "Epoch 76/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5233 - val_loss: 0.5144\n",
            "Epoch 77/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5234 - val_loss: 0.5143\n",
            "Epoch 78/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5233 - val_loss: 0.5147\n",
            "Epoch 79/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.5233 - val_loss: 0.5148\n",
            "Epoch 80/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5232 - val_loss: 0.5141\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5233 - val_loss: 0.5143\n",
            "Epoch 82/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5233 - val_loss: 0.5143\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5232 - val_loss: 0.5140\n",
            "121/121 [==============================] - 0s 3ms/step - loss: 0.5191\n",
            "Epoch 1/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 5.7613 - val_loss: 3.6512\n",
            "Epoch 2/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 2.5836 - val_loss: 1.8380\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 1.4192 - val_loss: 1.1159\n",
            "Epoch 4/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.9497 - val_loss: 0.8101\n",
            "Epoch 5/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.7484 - val_loss: 0.6760\n",
            "Epoch 6/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6572 - val_loss: 0.6137\n",
            "Epoch 7/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.6129 - val_loss: 0.5836\n",
            "Epoch 8/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5895 - val_loss: 0.5676\n",
            "Epoch 9/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5759 - val_loss: 0.5585\n",
            "Epoch 10/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5671 - val_loss: 0.5528\n",
            "Epoch 11/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5610 - val_loss: 0.5488\n",
            "Epoch 12/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5563 - val_loss: 0.5457\n",
            "Epoch 13/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5525 - val_loss: 0.5431\n",
            "Epoch 14/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5493 - val_loss: 0.5407\n",
            "Epoch 15/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5465 - val_loss: 0.5388\n",
            "Epoch 16/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5440 - val_loss: 0.5367\n",
            "Epoch 17/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5419 - val_loss: 0.5351\n",
            "Epoch 18/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5399 - val_loss: 0.5335\n",
            "Epoch 19/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5381 - val_loss: 0.5320\n",
            "Epoch 20/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5365 - val_loss: 0.5304\n",
            "Epoch 21/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5350 - val_loss: 0.5291\n",
            "Epoch 22/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5336 - val_loss: 0.5279\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5323 - val_loss: 0.5268\n",
            "Epoch 24/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5311 - val_loss: 0.5257\n",
            "Epoch 25/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5301 - val_loss: 0.5245\n",
            "Epoch 26/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5290 - val_loss: 0.5233\n",
            "Epoch 27/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5280 - val_loss: 0.5223\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5271 - val_loss: 0.5215\n",
            "Epoch 29/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5263 - val_loss: 0.5206\n",
            "Epoch 30/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5255 - val_loss: 0.5198\n",
            "Epoch 31/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5248 - val_loss: 0.5190\n",
            "Epoch 32/100\n",
            "242/242 [==============================] - 2s 6ms/step - loss: 0.5241 - val_loss: 0.5184\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5234 - val_loss: 0.5175\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - 1s 6ms/step - loss: 0.5228 - val_loss: 0.5170\n",
            "Epoch 35/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5223 - val_loss: 0.5165\n",
            "Epoch 36/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5218 - val_loss: 0.5158\n",
            "Epoch 37/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5213 - val_loss: 0.5153\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5208 - val_loss: 0.5148\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5204 - val_loss: 0.5144\n",
            "Epoch 40/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5200 - val_loss: 0.5138\n",
            "Epoch 41/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5196 - val_loss: 0.5133\n",
            "Epoch 42/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5193 - val_loss: 0.5128\n",
            "Epoch 43/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5189 - val_loss: 0.5126\n",
            "Epoch 44/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5186 - val_loss: 0.5120\n",
            "Epoch 45/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5183 - val_loss: 0.5116\n",
            "Epoch 46/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5181 - val_loss: 0.5113\n",
            "Epoch 47/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5178 - val_loss: 0.5111\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5175 - val_loss: 0.5109\n",
            "Epoch 49/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5173 - val_loss: 0.5106\n",
            "Epoch 50/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5171 - val_loss: 0.5101\n",
            "Epoch 51/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5168 - val_loss: 0.5100\n",
            "Epoch 52/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5167 - val_loss: 0.5098\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5165 - val_loss: 0.5094\n",
            "Epoch 54/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5163 - val_loss: 0.5094\n",
            "Epoch 55/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.5092\n",
            "Epoch 56/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5161 - val_loss: 0.5088\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5159 - val_loss: 0.5086\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5157 - val_loss: 0.5086\n",
            "Epoch 59/100\n",
            "242/242 [==============================] - 1s 4ms/step - loss: 0.5156 - val_loss: 0.5085\n",
            "Epoch 60/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5156 - val_loss: 0.5081\n",
            "Epoch 61/100\n",
            "242/242 [==============================] - 2s 7ms/step - loss: 0.5155 - val_loss: 0.5079\n",
            "Epoch 62/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5153 - val_loss: 0.5077\n",
            "Epoch 63/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5153 - val_loss: 0.5076\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - 1s 5ms/step - loss: 0.5151 - val_loss: 0.5073\n",
            "Epoch 65/100\n",
            "144/242 [================>.............] - ETA: 0s - loss: 0.4930"
          ]
        }
      ],
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0,1,2,3],\n",
        "    \"n_neurons\": np.arange(1,100),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter = 10, cv=3)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_valid, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
        "\"\"\"\n",
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "              validation_data = (X_valid, y_valid),\n",
        "              callbacks = [keras.callbacks.EarlyStopping(patience=10)])\n",
        "mse_test = keras_reg.score(X_test, y_test)\n",
        "y_pred = keras_reg.predict(X_new)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrGfMvebXCjI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "with open('textData.json') as textData:\n",
        "  data = json.load(textData)\n",
        "\"\"\"\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
        "preprocessor = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "encoder_inputs = preprocessor(text_input)\n",
        "encoder = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",\n",
        "    trainable=True)\n",
        "outputs = encoder(encoder_inputs)\n",
        "pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n",
        "sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_2rWbOYJyp5"
      },
      "outputs": [],
      "source": [
        "#model\n",
        "input = pooled_output\n",
        "hl1 = keras.layers.Dense(40, activation = 'relu')(input)\n",
        "\n",
        "hl2 = keras.layers.Dense(40, activation = 'relu')(hl1)\n",
        "hl3 = keras.layers.Dense(10, activation = 'relu')(hl2)\n",
        "concat = keras.layers.Concatenate()([input, hl3])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model = keras.Model(inputs = [input], outputs = [output])\n",
        "optimizer = keras.optimizers.SGD(clipvalue = 1.0)\n",
        "model.compile(loss = ['mse'], optimizer = optimizer)\n",
        "#loss function is mean squared error, optimizer is stochastic gd\n",
        "model.save('test_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "t8CxURBC3Oj2",
        "outputId": "df8c6aa6-0cec-4687-ed74-9899cbbb0626"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAbxNhtZxZKo",
        "outputId": "97797eca-7fe0-4779-c003-956e281abf53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras import utils\n",
        "import pathlib\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "#utils, pathlib, urllib is used for loading stuff in\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "vocab_size = 88544\n",
        "max_length = 250\n",
        "batch_size = 64\n",
        "(trainData, trainLabel),(testData, testLabel) = imdb.load_data(num_words = vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMhmEkgWdp91"
      },
      "outputs": [],
      "source": [
        "trainData = sequence.pad_sequences(trainData, max_length)\n",
        "testData = sequence.pad_sequences(testData, max_length)\n",
        "#for the freecodecamp seq rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htwo5FaHp-vt"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec\n",
        "BUFFER_SIZE = 10000#how many experiences/instances should be collected before doing anything regarding training\n",
        "BATCH_SIZE = 64#separate training dataset into sizes of x instances\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "#for the tf seq rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "PbaFdVDNBL4s",
        "outputId": "3cde41b2-845f-464f-aef9-c78aa597b2ff"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-93367ac29499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCABSIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#sets layer vocabulary tokens and pads if neccessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "VOCABSIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCABSIZE\n",
        ")\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "#sets layer vocabulary tokens and pads if neccessary\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]\n",
        "#sometimes not reversible due to unknown tokens and lack of character-based fallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKlnQ0glNSsR"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),#can go forward/back\n",
        "    tf.keras.layers.Dense(64, activation='relu'),#\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyLnDafOUgR7",
        "outputId": "6b43f847-d718-42b0-afd1-0b15d16c1588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 48s 91ms/step - loss: 0.6312 - accuracy: 0.5826 - val_loss: 0.4602 - val_accuracy: 0.7896\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 33s 83ms/step - loss: 0.3912 - accuracy: 0.8222 - val_loss: 0.3587 - val_accuracy: 0.8484\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 33s 83ms/step - loss: 0.3398 - accuracy: 0.8512 - val_loss: 0.3382 - val_accuracy: 0.8484\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 32s 81ms/step - loss: 0.3227 - accuracy: 0.8596 - val_loss: 0.3489 - val_accuracy: 0.8542\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.3138 - accuracy: 0.8662 - val_loss: 0.3355 - val_accuracy: 0.8448\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 33s 84ms/step - loss: 0.3095 - accuracy: 0.8670 - val_loss: 0.3308 - val_accuracy: 0.8620\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.3071 - accuracy: 0.8673 - val_loss: 0.3248 - val_accuracy: 0.8510\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 33s 82ms/step - loss: 0.3044 - accuracy: 0.8701 - val_loss: 0.3502 - val_accuracy: 0.8276\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 32s 82ms/step - loss: 0.3030 - accuracy: 0.8702 - val_loss: 0.3289 - val_accuracy: 0.8568\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 32s 82ms/step - loss: 0.2998 - accuracy: 0.8712 - val_loss: 0.3291 - val_accuracy: 0.8594\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "history=model.fit(train_dataset, epochs=10, validation_data=test_dataset, validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0u778QvpmuB"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPLNSKbGVrzP"
      },
      "source": [
        "above = tensorflow rnn tutorial\n",
        "below = tensorflow youtube freecodecamp tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUr6Kj7Wd-Wu"
      },
      "outputs": [],
      "source": [
        "def createRNNmodel(training, testing, size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(size, 32),#vectorize word tokens\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),#lstm cell\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')]#output\n",
        "    )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agf0iBTpekx_",
        "outputId": "d0ec86f0-b840-4ec1-f139-d90760f16a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          2833408   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,841,761\n",
            "Trainable params: 2,841,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "RNN = createRNNmodel(trainData, testData, vocab_size)\n",
        "RNN.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De7CpEs_fkjF",
        "outputId": "819fa736-1b6d-4dfc-d0e9-8e93f5940ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 14s 12ms/step - loss: 0.4214 - acc: 0.8079 - val_loss: 0.3208 - val_acc: 0.8670\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2404 - acc: 0.9093 - val_loss: 0.2703 - val_acc: 0.8898\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.1871 - acc: 0.9311 - val_loss: 0.2711 - val_acc: 0.8960\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.1520 - acc: 0.9467 - val_loss: 0.2859 - val_acc: 0.8796\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.1285 - acc: 0.9553 - val_loss: 0.2968 - val_acc: 0.8962\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1090 - acc: 0.9628 - val_loss: 0.3493 - val_acc: 0.8802\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.0934 - acc: 0.9690 - val_loss: 0.3088 - val_acc: 0.8936\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0803 - acc: 0.9722 - val_loss: 0.4995 - val_acc: 0.8590\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.0722 - acc: 0.9765 - val_loss: 0.3687 - val_acc: 0.8896\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.0608 - acc: 0.9792 - val_loss: 0.3170 - val_acc: 0.8826\n"
          ]
        }
      ],
      "source": [
        "RNN.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['acc'])\n",
        "#can be either rmsprop or adam (this the freecodecamp one)\n",
        "hist = RNN.fit(trainData, trainLabel, epochs = 10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFBMOtA82o6",
        "outputId": "99b0f258-85b5-42da-abae-6dfa119a16ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0    58   909     2    10    68  4151    31    11\n",
            "    17    10 18993     1   164    15    24  2755     0  2689]\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "text = \"my dog and i were offended by this movie i sued the director for his racist-dogist views\"\n",
        "def encode_text(text):#encodes words to number set 0 if no word has to be same\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens],max_length)[0]\n",
        "\n",
        "\"\"\"\n",
        "def decode_numbers(numbers):#decodes numbers if not 0 and sets back to letters\n",
        "  padding = 0\n",
        "  text = \"\"\n",
        "  for num in numbers:\n",
        "    if num != padding:\n",
        "      text += reverse_word_index[num] + \" \"\n",
        "  return text[:-1]\n",
        "\"\"\"\n",
        "\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF7Xy87fAoYa",
        "outputId": "bca03f37-cab5-4816-bc56-144c0612f2fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.97073764]\n"
          ]
        }
      ],
      "source": [
        "def predict(text):\n",
        "  encodedText = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encodedText\n",
        "  result = RNN.predict(pred)\n",
        "  return result[0]\n",
        "\n",
        "print(predict(\"According to all known laws of aviation, there is no way that a bee should be able to fly. Its wings are too small to get its fat little body off the ground. The bee, of course, flies anyway because bees don't care what humans think is impossible.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is CNN learning playground :P"
      ],
      "metadata": {
        "id": "FhkUnAj8nfCR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yMVUDOZGnd14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhRfVk6kdH1d"
      },
      "source": [
        "# This is the training for the actual nlp model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfZ7dEk_W-sA"
      },
      "source": [
        "Credit for instructions on tokenizing/preprocessing/neural network planning:\\\n",
        "Marco Vasquez @ Kaggle\\\n",
        "Tim @ Youtube\\\n",
        "Auréilin Géron @ O'Reily Media\\\n",
        "Kylie Ying @ Freecodecamp.org\\\n",
        "tensorflow.org website\\\n",
        "FARES SAYAH @ Kaggle\\\n",
        "Hayawi K, Shahriar S, Serhani MA, Taleb I, Mathew SS. ANTi-Vax: a novel Twitter dataset for COVID-19 vaccine misinformation detection. Public Health. 2022;203:23-30. doi:10.1016/j.puhe.2021.11.022\\\n",
        "Samikshya Siwakoti, Kamya Yadav, Isra Thange, Nicola Bariletto, Luca Zanotti, Alaa Ghoneim, and Jacob N. Shapiro. Localized Misinformation in a Global Pandemic: Report on COVID-19 Narratives around the World. Empirical Study of Conflict, Princeton University, pages 1-68, March 2021. URL https://esoc.princeton.edu/publications/localized-misinformation-global-pandemic-report-covid-19-narratives-around-world. \\\n",
        "\n",
        "\n",
        "\n",
        "Credit for datasets:\\\n",
        "Poynter.org\n",
        "Steven @ Kaggle\n",
        "Princeton\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflowjs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "adsvb14B155r",
        "outputId": "6545b2da-cef8-402c-8cc9-21cbebf26e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.8.0-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax<0.6.3,>=0.6.2 (from tensorflowjs)\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.9/189.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.0.0)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.13)\n",
            "Requirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.12.0)\n",
            "Collecting tensorflow-decision-forests>=1.3.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.13.0)\n",
            "Collecting packaging~=20.9 (from tensorflowjs)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.40)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (13.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (6.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging~=20.9->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (1.5.3)\n",
            "Collecting tensorflow<3,>=2.12.0 (from tensorflowjs)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.3.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.14,>=2.13 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.1.1 (from flax<0.6.3,>=0.6.2->tensorflowjs)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.4.13+cuda11.cudnn86)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, typing-extensions, tensorflow-estimator, packaging, keras, tensorboard, tensorflow, flax, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.7.0\n",
            "    Uninstalling flax-0.7.0:\n",
            "      Successfully uninstalled flax-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flax-0.6.2 keras-2.13.1 packaging-20.9 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-decision-forests-1.5.0 tensorflow-estimator-2.13.0 tensorflowjs-4.8.0 typing-extensions-4.5.0 wurlitzer-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN8JG_lAH4Du"
      },
      "source": [
        "import modules for preprocessing and model development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlvTAuObdPH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ef16bf-c37f-4ad6-aa45-49d629973003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!pip -q install transformers\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive')\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow_hub as hub\n",
        "import sklearn as sk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDW5BOJtZREc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5YrsGZkIWEA"
      },
      "source": [
        "read and clean/preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. load data from google drive"
      ],
      "metadata": {
        "id": "0zzN9aFTw35o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU5lKJDS6-Ph"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/My Drive/archive (1)')\n",
        "import pandas as pd\n",
        "databox = pd.DataFrame(pd.read_csv('news_articles.csv'))\n",
        "more_false_data = pd.DataFrame(pd.read_csv('poynter_data.csv'))\n",
        "esocData = pd.DataFrame(pd.read_csv('esoc.csv'))\n",
        "nlmData = pd.DataFrame(pd.read_csv('ids.csv'))\n",
        "trueorfalsenlm = pd.DataFrame(pd.read_csv('VaxMisinfoData.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trueorfalsenlm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "C8X7ONVuw-uo",
        "outputId": "b973727f-b2c7-42bb-8bf6-aaa237fdc873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id  is_misinfo\n",
              "0      1344795424855642112           0\n",
              "1      1344794858133860353           0\n",
              "2      1344794822691983360           0\n",
              "3      1344794752819077123           1\n",
              "4      1344792070507134977           0\n",
              "...                    ...         ...\n",
              "15068  1413087751474397186           0\n",
              "15069  1413087030578401283           0\n",
              "15070  1413085793397186565           1\n",
              "15071  1413085519710363648           0\n",
              "15072  1413085365745774593           0\n",
              "\n",
              "[15073 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0253cd92-f3f0-4a4c-96dd-0e78cb356bc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>is_misinfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1344795424855642112</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1344794858133860353</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1344794822691983360</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1344794752819077123</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1344792070507134977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15068</th>\n",
              "      <td>1413087751474397186</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15069</th>\n",
              "      <td>1413087030578401283</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15070</th>\n",
              "      <td>1413085793397186565</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15071</th>\n",
              "      <td>1413085519710363648</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15072</th>\n",
              "      <td>1413085365745774593</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15073 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0253cd92-f3f0-4a4c-96dd-0e78cb356bc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-5c9963e3-3721-43f9-838c-49ed97112cc7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c9963e3-3721-43f9-838c-49ed97112cc7')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-5c9963e3-3721-43f9-838c-49ed97112cc7 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0253cd92-f3f0-4a4c-96dd-0e78cb356bc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0253cd92-f3f0-4a4c-96dd-0e78cb356bc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "some data and labels are separate datasets so this will concatenate them together"
      ],
      "metadata": {
        "id": "3PMPatoCxClX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eJnl9VoAdu1"
      },
      "outputs": [],
      "source": [
        "trueorfalsenlm = trueorfalsenlm.assign(text=nlmData['text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rihHoHNX0SDz"
      },
      "source": [
        "See how they are all structured\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Clean data\n",
        "\n",
        "\n",
        "*   tweet id was not needed in nlm dataset\n",
        "*   the name label will be used in all datasets to represent the column for label (0 as real, 1 as fake, due to the goal of detecting false data)\n",
        "*   nlm dataset was messed up after a certain point, was trimmed\n",
        "*   databox dataset had string labels, convert to number\n",
        "*   databox dataset will be added by instance to train, so delete all irrelevant\n",
        "*   rename databox column to standardize all data column names to 'text'\n",
        "*   esoc data was also messed up after instance 6000 so it was trimmed too\n",
        "*   more_false_data needed a label column so a Pandas Series of 1.0s were added\n",
        "*   esoc data has irrelevant columns, those were deleted\n",
        "*   esoc data based on researching TYPES of misinfo, so all instances are false; labels are all 1.0s\n",
        "*   rename esoc text column to 'text' to standardize for the merging\n",
        "\n"
      ],
      "metadata": {
        "id": "p2kE0EGcxPdI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUsIMhLb7_tO"
      },
      "outputs": [],
      "source": [
        "trueorfalsenlm = trueorfalsenlm.drop(axis = 1, columns = ['id'])\n",
        "trueorfalsenlm['is_misinfo'] = trueorfalsenlm['is_misinfo'].astype(float)\n",
        "trueorfalsenlm.rename(columns = {'is_misinfo':'label'}, inplace = True)\n",
        "trueorfalsenlm = trueorfalsenlm[:12381]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WcBnPtZ1fyi-",
        "outputId": "dca0da0a-11f6-4fd0-8c5e-eb178c729090"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0    0.0  print pay back money plus interest entire fami...\n",
              "1    0.0  attorney general loretta lynch plead fifth bar...\n",
              "2    0.0  red state fox news sunday reported morning ant...\n",
              "3    0.0  email kayla mueller prisoner tortured isis cha...\n",
              "4    0.0  email healthcare reform make america great sin..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d0cd806e-08bf-4010-a465-789da8f15989\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0cd806e-08bf-4010-a465-789da8f15989')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-91b74618-4f60-408c-8422-2089496cbc05\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91b74618-4f60-408c-8422-2089496cbc05')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-91b74618-4f60-408c-8422-2089496cbc05 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0cd806e-08bf-4010-a465-789da8f15989 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0cd806e-08bf-4010-a465-789da8f15989');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "databox['label'].replace ({'Fake': 1, 'Real': 0}, inplace=True)\n",
        "databox = databox.drop(axis = 1, columns = ['author','published','title','text','language','site_url','main_img_url','type','title_without_stopwords','hasImage'])\n",
        "databox.rename(columns = {'text_without_stopwords':'text'}, inplace = True)\n",
        "\n",
        "databox.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vHJF2shS0Qli",
        "outputId": "428a25dd-93bb-44a9-e83c-79b65a7373a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "0       1.0   A post that has a list of recommendations to ...\n",
              "1       1.0   The first person to received a Chinese COVID-...\n",
              "2       1.0   A video from family doctor Natalia Prego Canc...\n",
              "3       1.0   RNA-based COVID-19 vaccines can turn humans i...\n",
              "4       1.0   A post that shows a doctor from Santiago del ...\n",
              "...     ...                                                ...\n",
              "7539    1.0   The coronavirus was created in a lab and pate...\n",
              "7540    1.0   A Chinese market caused the new coronavirus (...\n",
              "7541    1.0   The peak of the new coronavirus will happen i...\n",
              "7542    1.0   Stores and supermarkets in Veracruz (Mexico) ...\n",
              "7543    1.0   A chain message circulated on Tuesday, Jan. 1...\n",
              "\n",
              "[7544 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d644a291-9f2c-44cd-a016-4b9b6653336f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A post that has a list of recommendations to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The first person to received a Chinese COVID-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A video from family doctor Natalia Prego Canc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>RNA-based COVID-19 vaccines can turn humans i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A post that shows a doctor from Santiago del ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7539</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The coronavirus was created in a lab and pate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7540</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A Chinese market caused the new coronavirus (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The peak of the new coronavirus will happen i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7542</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Stores and supermarkets in Veracruz (Mexico) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7543</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A chain message circulated on Tuesday, Jan. 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7544 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d644a291-9f2c-44cd-a016-4b9b6653336f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-492755a8-17c6-4943-8fed-2d586c263573\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-492755a8-17c6-4943-8fed-2d586c263573')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-492755a8-17c6-4943-8fed-2d586c263573 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d644a291-9f2c-44cd-a016-4b9b6653336f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d644a291-9f2c-44cd-a016-4b9b6653336f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "more_false_data.head()\n",
        "more_false_data['label'] = float(1)\n",
        "more_false_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMdVvZHTf7iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6536c096-f81e-43db-d983-81c5ae36dd46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          English\n",
              "1          English\n",
              "2          English\n",
              "3          English\n",
              "4          English\n",
              "           ...    \n",
              "5608    Portuguese\n",
              "5609    Portuguese\n",
              "5610    Portuguese\n",
              "5611    Portuguese\n",
              "5612    Portuguese\n",
              "Name: Primary_Language, Length: 5613, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "esocData = esocData[:5613]\n",
        "esocData = esocData.assign(label=float(1))\n",
        "newPD = pd.DataFrame()\n",
        "esocData['Primary_Language']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "esocData.drop(axis = 1, columns = ['s_no','Notes','Region','Reported_On','Additional_Reporting','Retrieve_from_1','Retrieve_from_2','Retrieve_from_3','Twitter_Reference','Direct_Post_1','Direct_Post_2','Direct_Post_3','Direct_Post_4','Title','Publication_Date','Entry_Date','Primary_Country','Secondary_Country','Primary_Language','Secondary_Language','Main_Narrative','Recoded_Main_Narrative','Recoded_Narrative_Coder','ChainMsg_or_Email','Motive','Motive_Description','Source','Source_Description','Distrib_Channel','Misinfo_Type','Key_Words','Summary','Coder'], inplace=True)\n",
        "esocData.rename(columns = {'Narrative_Description':'text'}, inplace = True)"
      ],
      "metadata": {
        "id": "aVqBhKs3_nn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KMyIGvSg8JU_",
        "outputId": "870089c8-b3ad-4eaa-cc34-ed55434c1534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     Hindi language YouTube account saying COVID-19...    1.0\n",
              "1     Twitter user posting a compilation video of pe...    1.0\n",
              "2     Twitter user posting a video of a celebrity ea...    1.0\n",
              "3         Chain message of NYPD containment responses.     1.0\n",
              "4     Chain message of Indian Health Ministry respon...    1.0\n",
              "...                                                 ...    ...\n",
              "5608                        Coffee can prevent COVID-19    1.0\n",
              "5609               The number of COVID-19 deaths is 946    1.0\n",
              "5610       Facemasks donated by China contain the virus    1.0\n",
              "5611  low-quality masks were distributed by the Braz...    1.0\n",
              "5612  Flu vaccine would increase the risk of getting...    1.0\n",
              "\n",
              "[5613 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-380b4395-591e-4962-a7a1-778a6d08c71a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hindi language YouTube account saying COVID-19...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter user posting a compilation video of pe...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter user posting a video of a celebrity ea...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chain message of NYPD containment responses.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chain message of Indian Health Ministry respon...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5608</th>\n",
              "      <td>Coffee can prevent COVID-19</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5609</th>\n",
              "      <td>The number of COVID-19 deaths is 946</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5610</th>\n",
              "      <td>Facemasks donated by China contain the virus</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5611</th>\n",
              "      <td>low-quality masks were distributed by the Braz...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5612</th>\n",
              "      <td>Flu vaccine would increase the risk of getting...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5613 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-380b4395-591e-4962-a7a1-778a6d08c71a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f70e6748-2bb4-4c97-b1af-a8c2f5673ee5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f70e6748-2bb4-4c97-b1af-a8c2f5673ee5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f70e6748-2bb4-4c97-b1af-a8c2f5673ee5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-380b4395-591e-4962-a7a1-778a6d08c71a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-380b4395-591e-4962-a7a1-778a6d08c71a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#esocData = esocData.iloc[:, [1,0]]\n",
        "esocData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-k53V7_g74F"
      },
      "source": [
        "concatenate the dataset before applying the address remover because addresses and handles are common on multiple datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KJSTrVotvl0L",
        "outputId": "69ea5466-79d8-4bf6-8276-bdcd9333c52b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "0       0.0  print pay back money plus interest entire fami...\n",
              "1       0.0  attorney general loretta lynch plead fifth bar...\n",
              "2       0.0  red state fox news sunday reported morning ant...\n",
              "3       0.0  email kayla mueller prisoner tortured isis cha...\n",
              "4       0.0  email healthcare reform make america great sin...\n",
              "...     ...                                                ...\n",
              "7539    1.0   The coronavirus was created in a lab and pate...\n",
              "7540    1.0   A Chinese market caused the new coronavirus (...\n",
              "7541    1.0   The peak of the new coronavirus will happen i...\n",
              "7542    1.0   Stores and supermarkets in Veracruz (Mexico) ...\n",
              "7543    1.0   A chain message circulated on Tuesday, Jan. 1...\n",
              "\n",
              "[27634 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7ab03c9f-d337-479d-9cc6-ccfa07e87dc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>print pay back money plus interest entire fami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>attorney general loretta lynch plead fifth bar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>red state fox news sunday reported morning ant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>email kayla mueller prisoner tortured isis cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>email healthcare reform make america great sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7539</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The coronavirus was created in a lab and pate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7540</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A Chinese market caused the new coronavirus (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>1.0</td>\n",
              "      <td>The peak of the new coronavirus will happen i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7542</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Stores and supermarkets in Veracruz (Mexico) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7543</th>\n",
              "      <td>1.0</td>\n",
              "      <td>A chain message circulated on Tuesday, Jan. 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27634 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab03c9f-d337-479d-9cc6-ccfa07e87dc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-22b7ab00-e16a-4e81-9c8b-0032e5587164\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22b7ab00-e16a-4e81-9c8b-0032e5587164')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-22b7ab00-e16a-4e81-9c8b-0032e5587164 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ab03c9f-d337-479d-9cc6-ccfa07e87dc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ab03c9f-d337-479d-9cc6-ccfa07e87dc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data = pd.concat([databox, esocData, trueorfalsenlm, more_false_data])\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCJOKGxbUo7I"
      },
      "source": [
        "remove @, 'photo by name/Getty images',dates, links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_1NlzZA-Gob"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "#TODO: strip the dataset of all emails, twitter acc prof, image references, capital letters\n",
        "web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "user = re.compile(r\"(?i)@[a-z0-9_]+\")\n",
        "regex_list = [web_address, user]\n",
        "# we then use the sub method to replace anything matching\n",
        "\n",
        "def clean(dataset):\n",
        "  \"\"\"clean from stopwords and other stuff, convert to list, back to string\"\"\"\n",
        "  if isinstance(dataset, float):\n",
        "    dataset = 'a'\n",
        "  STOPWORDS = stopwords.words('english')\n",
        "    # Check characters to see if they are in punctuation\n",
        "  nopunc = [char for char in dataset if char not in string.punctuation and all(regex.search(char.lower()) is None for regex in regex_list)]\n",
        "\n",
        "    # Join the characters again to form the string.\n",
        "  nopunc = ''.join(nopunc)\n",
        "\n",
        "    # Now just remove any stopwords\n",
        "  return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])\n",
        "  return \" \".join(word\n",
        "                for word in nopunc.split()\n",
        "                if word.lower() not in stopwords.words(\"english\") and all(regex.search(word.lower()) is None for regex in regex_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DQR9SC_-7-9"
      },
      "outputs": [],
      "source": [
        "esocData['text'] = esocData['text'].apply(clean)\n",
        "trueorfalsenlm['text'] = trueorfalsenlm['text'].apply(clean)\n",
        "more_false_data['text'] = more_false_data['text'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "esocData[esocData['label']!=0.0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PYEEKcxqTJzf",
        "outputId": "e96f52eb-4e26-46a6-dce8-09f8c4fd39a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     Hindi language YouTube account saying COVID19 ...    1.0\n",
              "1     Twitter user posting compilation video people ...    1.0\n",
              "2     Twitter user posting video celebrity eating ba...    1.0\n",
              "3              Chain message NYPD containment responses    1.0\n",
              "4        Chain message Indian Health Ministry responses    1.0\n",
              "...                                                 ...    ...\n",
              "5608                             Coffee prevent COVID19    1.0\n",
              "5609                          number COVID19 deaths 946    1.0\n",
              "5610              Facemasks donated China contain virus    1.0\n",
              "5611  lowquality masks distributed Brazilian government    1.0\n",
              "5612    Flu vaccine would increase risk getting COVID19    1.0\n",
              "\n",
              "[5613 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cadf634c-d9de-4265-bbe5-db9193c3df24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hindi language YouTube account saying COVID19 ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Twitter user posting compilation video people ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Twitter user posting video celebrity eating ba...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chain message NYPD containment responses</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Chain message Indian Health Ministry responses</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5608</th>\n",
              "      <td>Coffee prevent COVID19</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5609</th>\n",
              "      <td>number COVID19 deaths 946</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5610</th>\n",
              "      <td>Facemasks donated China contain virus</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5611</th>\n",
              "      <td>lowquality masks distributed Brazilian government</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5612</th>\n",
              "      <td>Flu vaccine would increase risk getting COVID19</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5613 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cadf634c-d9de-4265-bbe5-db9193c3df24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cadf634c-d9de-4265-bbe5-db9193c3df24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cadf634c-d9de-4265-bbe5-db9193c3df24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzn6yzghw0e7"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([esocData, trueorfalsenlm, more_false_data, databox], sort = False, ignore_index = True)\n",
        "data = data.iloc[:27584]\n",
        "data = data.fillna(0)\n",
        "data['label'] = data['label'].astype(int)\n",
        "data = data[['label','text']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['label'] == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W2FFSizXTcO4",
        "outputId": "d243821a-77c4-463a-8e3a-62e315ae76d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text\n",
              "0          1  Hindi language YouTube account saying COVID19 ...\n",
              "1          1  Twitter user posting compilation video people ...\n",
              "2          1  Twitter user posting video celebrity eating ba...\n",
              "3          1           Chain message NYPD containment responses\n",
              "4          1     Chain message Indian Health Ministry responses\n",
              "...      ...                                                ...\n",
              "27526      1  democrats perpetually circle wagons republican...\n",
              "27527      1  election crossroads socialism capitalism exclu...\n",
              "27528      1  print applaud integrity condemn selling allow ...\n",
              "27529      1  new country women minorities hit hardest ann c...\n",
              "27530      1  trump vs clinton risk vs disaster larry elder ...\n",
              "\n",
              "[19305 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57c26ccc-e7c9-429e-a9b1-fdca473fe5f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hindi language YouTube account saying COVID19 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Twitter user posting compilation video people ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Twitter user posting video celebrity eating ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Chain message NYPD containment responses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Chain message Indian Health Ministry responses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27526</th>\n",
              "      <td>1</td>\n",
              "      <td>democrats perpetually circle wagons republican...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27527</th>\n",
              "      <td>1</td>\n",
              "      <td>election crossroads socialism capitalism exclu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27528</th>\n",
              "      <td>1</td>\n",
              "      <td>print applaud integrity condemn selling allow ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27529</th>\n",
              "      <td>1</td>\n",
              "      <td>new country women minorities hit hardest ann c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27530</th>\n",
              "      <td>1</td>\n",
              "      <td>trump vs clinton risk vs disaster larry elder ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19305 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57c26ccc-e7c9-429e-a9b1-fdca473fe5f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57c26ccc-e7c9-429e-a9b1-fdca473fe5f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57c26ccc-e7c9-429e-a9b1-fdca473fe5f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR29yhj5J3jH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train, val, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYC-Kl7Ngtku",
        "outputId": "9f87dfb5-fc28-48cb-bf42-99f1c4197db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18816    Brazilian states receive R 16450 extra funding...\n",
              "17294    Got second vaccine I’m good go👍 httpstcoZnLvxL...\n",
              "14313    take birth control don’t worry what’s dat vaccine\n",
              "20311    Ghana Education Service confirms date schools ...\n",
              "2804      independent MLA advised people get COVID19 tests\n",
              "                               ...                        \n",
              "11135    got first dose Pfizer vaccine today hoped feel...\n",
              "1744     China participated promotion false information...\n",
              "20646    post shared repeatedly Facebook Sri Lankan Fac...\n",
              "22859    Paraguayans go “even buy bread” incubation per...\n",
              "6001     Received first dose Pfizer COVID19 vaccine tod...\n",
              "Name: text, Length: 16550, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NmjnWWxJmQV"
      },
      "outputs": [],
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  \"\"\"returns a PrefetchDataset object with instances truncated to batch_size\"\"\"\n",
        "  df = dataframe.copy()\n",
        "  labels = df.pop('label')\n",
        "  df = df['text']\n",
        "  ds = tf.data.Dataset.from_tensor_slices((df, labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_aZsfIr3Wqyb",
        "outputId": "74599d91-247f-4626-dcf7-3e2d0d985e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text\n",
              "18816      1  Brazilian states receive R 16450 extra funding...\n",
              "17294      1  Got second vaccine I’m good go👍 httpstcoZnLvxL...\n",
              "14313      0  take birth control don’t worry what’s dat vaccine\n",
              "20311      1  Ghana Education Service confirms date schools ...\n",
              "2804       1   independent MLA advised people get COVID19 tests\n",
              "...      ...                                                ...\n",
              "11135      0  got first dose Pfizer vaccine today hoped feel...\n",
              "1744       1  China participated promotion false information...\n",
              "20646      1  post shared repeatedly Facebook Sri Lankan Fac...\n",
              "22859      1  Paraguayans go “even buy bread” incubation per...\n",
              "6001       1  Received first dose Pfizer COVID19 vaccine tod...\n",
              "\n",
              "[16550 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0aaa2218-383c-4eef-ac05-b5aa6d6b09bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18816</th>\n",
              "      <td>1</td>\n",
              "      <td>Brazilian states receive R 16450 extra funding...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17294</th>\n",
              "      <td>1</td>\n",
              "      <td>Got second vaccine I’m good go👍 httpstcoZnLvxL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14313</th>\n",
              "      <td>0</td>\n",
              "      <td>take birth control don’t worry what’s dat vaccine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20311</th>\n",
              "      <td>1</td>\n",
              "      <td>Ghana Education Service confirms date schools ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2804</th>\n",
              "      <td>1</td>\n",
              "      <td>independent MLA advised people get COVID19 tests</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11135</th>\n",
              "      <td>0</td>\n",
              "      <td>got first dose Pfizer vaccine today hoped feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>1</td>\n",
              "      <td>China participated promotion false information...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20646</th>\n",
              "      <td>1</td>\n",
              "      <td>post shared repeatedly Facebook Sri Lankan Fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22859</th>\n",
              "      <td>1</td>\n",
              "      <td>Paraguayans go “even buy bread” incubation per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>1</td>\n",
              "      <td>Received first dose Pfizer COVID19 vaccine tod...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16550 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0aaa2218-383c-4eef-ac05-b5aa6d6b09bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0aaa2218-383c-4eef-ac05-b5aa6d6b09bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0aaa2218-383c-4eef-ac05-b5aa6d6b09bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xre8Ht8PJnJW"
      },
      "outputs": [],
      "source": [
        "train = df_to_dataset(train)\n",
        "val = df_to_dataset(val)\n",
        "test = df_to_dataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ_kWgMXSlDa",
        "outputId": "007bcff0-1501-4d3c-b843-571ea4f544a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxtP92EEUGCE"
      },
      "source": [
        "streamline the text, make all lowercase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlCotVi5IQ6k"
      },
      "source": [
        "checking dataset structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfet6fGINvd"
      },
      "source": [
        "split data into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGsgANa9J-l4"
      },
      "source": [
        "count # of unique words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivdhv22eIAHn"
      },
      "source": [
        ":The embeddings can be used as a piece to build a larger machine learning system that is able to draw insights about COVID-19 research.\n",
        "last touch: the input layer has a max sequence of 100 bc discord messages rarely have more than 100 words/tokens (anecdotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huRS2Q8qoBMu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "#english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\n",
        "\"\"\"\n",
        "this is the reference for the encoder and the embedder\n",
        "the preprocessor converts the words into an array that is fed to the model\n",
        "the encoder takes it and converts it to unique # representation (like oneHot)\n",
        "the embedding vectorizes the word-number combination in a way that emphasizes\n",
        "context (think about dots on a 3d graph and those dots' location represented\n",
        "context in regards to each other)\n",
        "model will be trained on data, and embeddings will be fitted to accomodate\n",
        "after saved, specialized embedding/encoding/trained model will process new data\n",
        "outside of set\n",
        "\n",
        "from stkovf: LSTM layers expect 3D input tensors, but Dense outputs only 2D\n",
        "fix:\n",
        "\"\"\"\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(100,), dtype=tf.string)\n",
        "\n",
        "embed = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\",\n",
        "                       input_shape = [], dtype=tf.string, trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6HJemDQoB-M",
        "outputId": "1af83e7b-ce2b-425f-9638-5b640caf5e2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "array([b'Claims Dr Anthony Fauci currently advising wearing face masks',\n",
              "       b'plan get commissions sketched tomorrow get second vaccine wednesday die rest week',\n",
              "       b'\\xe2\\x9a\\xa0\\xef\\xb8\\x8f\\xe2\\x9a\\xa0\\xef\\xb8\\x8f\\xe2\\x9a\\xa0\\xef\\xb8\\x8fWARNING\\xe2\\x9a\\xa0\\xef\\xb8\\x8f\\xe2\\x9a\\xa0\\xef\\xb8\\x8f\\xe2\\x9a\\xa0\\xef\\xb8\\x8f BOSTON coercing elderly getting experimental genetically modifying Covid agent call vaccine order get apartments services REAL FOLKS aunt lied given \\xe2\\x80\\x9cCovid vaccine\\xe2\\x80\\x9d',\n",
              "       b'Claims Tanzania reported 16467 COVID19 cases 1293 deaths 118 recoveries',\n",
              "       b'Suicide rates Berlin rose 300 percent lockdown',\n",
              "       b'got second dose covid vaccine felt like crap woke',\n",
              "       b'Trump claims COVID19 restrictions partisan ploy',\n",
              "       b'Claim Dr Fauci said every American microchipped',\n",
              "       b'Tips new coronavirus Holding breath drinking water',\n",
              "       b'Person fainted subway station COVID19',\n",
              "       b'Vaccine Vaccine \\xe2\\x80\\x93 Answer Experimental Gene Therapy httpstco8ReJmPuInQ via httpstwittercomUnityNewsNet',\n",
              "       b'viral text message claims FDA approved use chloroquine COVID19 patients pharma company Novartis announced studies proving chloroquine cures COVID19',\n",
              "       b'Personally cannot see difference untested vaccine used globally genocide I\\xe2\\x80\\x99m perhaps little oldfashioned liking see drugs vaccines properly tested rolled large populations Vernon Coleman',\n",
              "       b'\\xe2\\x80\\x9cAccording CDC far year Florida 1762 deaths COVID19 5185 pneumonia Average pneumonia deaths Florida 20132018 time period 918\\xe2\\x80\\x9d',\n",
              "       b'bite icecream dont worry whats vaccine',\n",
              "       b'anti vax folk qualify vaccine refuse get y\\xe2\\x80\\x99all give instead wanna get vaccinated BAD GetVaccinated',\n",
              "       b'Packets spice included Sri Lankan government ration kits COVID19 lockdown branded local political partys logo',\n",
              "       b'Got first vaccine lessgo',\n",
              "       b'recorded audio series phone conversations former president bill clinton mistress gennifer flowers recently surfaced one recordings clinton governor arkansas heard advising flowers deny claims aided getting state job ever asked youd talked say says related stories bill clinton leads crowd litany obamacares failures wikileaks bill clinton accepted expensive gifts cgi donors activist documented dncs dirty tricks operation joining trump debate recording released wednesday breitbart time recording media asking many questions clintons affair flowers worried barrage questions could inevitably lead inquires landed job administrative assistant arkansas appeal tribunal complaint filed anonymous woman felt flowers relationship clinton kept getting job woman claimed qualified audio clinton heard coaching flowers best deal woman subsequent questions may arise sections audio recordings dealing state job given news media came one day clinton appeared minutes wife hillary current democratic presidential nominee blatantly denying romantic relationship flowers however deposition sexual harassment lawsuit filed paula jones clinton would eventually admit sexual interaction flowers trending stories frustrated media bias trump campaign takes case directly voters nightly show facebook rnc official takes cnn host task claiming media bias hannity proposes sendoff obama event trump presidency flowers recorded conversations clinton governor prior campaign president wasnt turned full original recordings breitbart reporter timing leak comes time amid recent sexual harassment allegations republican nominee donald trump clinton number people questioning treatment women think',\n",
              "       b'picture reporter protective medical gear example American media \\xe2\\x80\\x9chypes\\xe2\\x80\\x9d COVID19 pandemic',\n",
              "       b'\\xf0\\x9f\\x91\\x87\\xf0\\x9f\\x8f\\xbc\\xf0\\x9f\\x91\\x80 VaccinesWork COVID19 Keep UKs latest safety vaccine guidance httpstco6cjoyJ1Ns5',\n",
              "       b'Thank JennerInstitute UniofOxford NHSEngland DHSCgovuk AstraZeneca lovely volunteers LBHF vaccination centre VaccinesWork VaccinationCovid vaccinated vaccination httpstcoTu4B6kk752',\n",
              "       b'image showing lighting Burj Khalifa Dubai colors Syrian flag solidarity Syrians facing coronavirus',\n",
              "       b'blog article stating Bill Gates arrested FBI created new coronavirus',\n",
              "       b'Red soap white handkerchiefs specific types light bulbs prevent coronavirus infection',\n",
              "       b'first vaccine done haven\\xe2\\x80\\x99t passed yet yay',\n",
              "       b'Coronavirus dies 2627 degrees temperature according UNICEF',\n",
              "       b'father believes COVID vaccine depopulation technique Bill Gates Bezos got anyways hes worried fertility lifespane days partial success',\n",
              "       b'Receiving first dose vaccine later today wish luck \\xe2\\x9d\\xa4',\n",
              "       b'Second Pfizer vaccine shot installed reactions Ive noticed far',\n",
              "       b'vaccine 5G towers else missed period Depopulation real',\n",
              "       b'WA Govt Notice Administer Covid19 Poison Vaccine Public 1 httpstcomHe9BXKNDg'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "list(train)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWwoU4_Nr8GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9515ef9-1a53-4544-eefd-d67dc02c2326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(embed)\n",
        "model.add(tf.keras.layers.Dense(8, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(8, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adamax',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wbS1qqCcIbk",
        "outputId": "51025232-d380-404c-8fcb-14fa6e067d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "518/518 [==============================] - 5s 3ms/step - loss: 0.6904 - accuracy: 0.5692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6903591156005859, 0.5691843032836914]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.evaluate(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riGI1NVi09uL",
        "outputId": "2a2294c3-2ea6-446e-f49d-80b7671fffb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.5710\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6912930011749268, 0.5709624886512756]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "model.evaluate(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DspxIxA01GkO",
        "outputId": "86538b34-f4fd-4772-c3bf-47ddc05ee650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "518/518 [==============================] - 86s 162ms/step - loss: 0.6115 - accuracy: 0.6955 - val_loss: 0.5337 - val_accuracy: 0.7035\n",
            "Epoch 2/10\n",
            "518/518 [==============================] - 52s 101ms/step - loss: 0.4938 - accuracy: 0.7282 - val_loss: 0.4384 - val_accuracy: 0.7562\n",
            "Epoch 3/10\n",
            "518/518 [==============================] - 37s 71ms/step - loss: 0.4354 - accuracy: 0.7548 - val_loss: 0.4057 - val_accuracy: 0.7714\n",
            "Epoch 4/10\n",
            "518/518 [==============================] - 28s 55ms/step - loss: 0.4058 - accuracy: 0.7663 - val_loss: 0.3921 - val_accuracy: 0.7781\n",
            "Epoch 5/10\n",
            "518/518 [==============================] - 24s 47ms/step - loss: 0.3876 - accuracy: 0.7737 - val_loss: 0.3838 - val_accuracy: 0.7818\n",
            "Epoch 6/10\n",
            "518/518 [==============================] - 23s 45ms/step - loss: 0.3735 - accuracy: 0.7847 - val_loss: 0.3796 - val_accuracy: 0.7843\n",
            "Epoch 7/10\n",
            "518/518 [==============================] - 21s 40ms/step - loss: 0.3597 - accuracy: 0.7970 - val_loss: 0.3791 - val_accuracy: 0.7859\n",
            "Epoch 8/10\n",
            "518/518 [==============================] - 19s 36ms/step - loss: 0.3494 - accuracy: 0.8089 - val_loss: 0.3761 - val_accuracy: 0.7877\n",
            "Epoch 9/10\n",
            "518/518 [==============================] - 17s 33ms/step - loss: 0.3379 - accuracy: 0.8185 - val_loss: 0.3780 - val_accuracy: 0.7887\n",
            "Epoch 10/10\n",
            "518/518 [==============================] - 17s 32ms/step - loss: 0.3304 - accuracy: 0.8211 - val_loss: 0.3804 - val_accuracy: 0.7885\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(train, epochs = 10, validation_data = val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ImQW0qM13pp"
      },
      "outputs": [],
      "source": [
        "vectorizer = tf.keras.layers.TextVectorization(max_tokens = 2000)\n",
        "vectorizer.adapt(train.map(lambda txt, label: txt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35kDkocb1oIU"
      },
      "outputs": [],
      "source": [
        "modeLSTM = tf.keras.Sequential([\n",
        "  vectorizer,\n",
        "  tf.keras.layers.Embedding(\n",
        "      input_dim = len(vectorizer.get_vocabulary()),\n",
        "      output_dim = 12,\n",
        "      mask_zero = True\n",
        "  ),\n",
        "  tf.keras.layers.LSTM(12),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "\n",
        "])\n",
        "modeLSTM.compile(optimizer=tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\"\n",
        "),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch implementation of the above code\n",
        "#(GENERATED FROM CHATGPT FOR FUN, DID NOT CREATE BY HAND)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ModelLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, embedding_dim, hidden_dim):\n",
        "        super(ModelLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=0, mask_zero=True)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.dense1 = nn.Linear(hidden_dim, 10)\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.dense2 = nn.Linear(10, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, (hidden, _) = self.lstm(x)\n",
        "        x = self.dense1(hidden.squeeze(0))\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = ModelLSTM(input_dim=len(vectorizer.get_vocabulary()),\n",
        "                  output_dim=1,\n",
        "                  embedding_dim=12,\n",
        "                  hidden_dim=12)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-7)"
      ],
      "metadata": {
        "id": "qaPfQnUElZ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XWS9xtzqwxl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGiRJ9BZ3Xtc",
        "outputId": "996b0f37-0207-4116-8fc3-a5e9bf5de5bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "518/518 [==============================] - 80s 140ms/step - loss: 0.0000e+00 - accuracy: 0.3008 - val_loss: 0.0000e+00 - val_accuracy: 0.3061\n",
            "Epoch 2/10\n",
            "518/518 [==============================] - 41s 79ms/step - loss: 0.0000e+00 - accuracy: 0.3004 - val_loss: 0.0000e+00 - val_accuracy: 0.3061\n",
            "Epoch 3/10\n",
            "518/518 [==============================] - 27s 53ms/step - loss: 0.0000e+00 - accuracy: 0.3004 - val_loss: 0.0000e+00 - val_accuracy: 0.3061\n",
            "Epoch 4/10\n",
            "518/518 [==============================] - 20s 38ms/step - loss: 0.0000e+00 - accuracy: 0.3004 - val_loss: 0.0000e+00 - val_accuracy: 0.3061\n",
            "Epoch 5/10\n",
            "486/518 [===========================>..] - ETA: 1s - loss: 0.0000e+00 - accuracy: 0.2998"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "history = modeLSTM.fit(train, epochs=10, validation_data = val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-xwY013nYbf",
        "outputId": "7c75fa20-f8c1-4365-efb2-529a3de56be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 2s 9ms/step - loss: 0.4369 - accuracy: 0.7834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43692976236343384, 0.7833967804908752]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "modeLSTM.evaluate(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model actually works to an extent. Granted, the results are the inverse of the label predictions, but a general pattern is detected. There are some anomalies, like the score given to 'covid was created in a lab', but since some of the data date back to early in the pandemic and was conducted before more research was done on the virus, speculation and uncertainty of truth is expected. In addition, the model seems to skew more sensitive towards political messages rather than misinformation purely based on the charasteristics of the disease. The current tests have stopwords directly fed into the model, so perhaps that might tamper with the weights and biases that were tuned on the preprocessed dataset."
      ],
      "metadata": {
        "id": "ygZMBIJqEOQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['bioweapon'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmzArczk_lv7",
        "outputId": "54b003f9-eb79-4421-ff93-3e7a55b1162f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35603696]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['pelosi'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9xSAsh6Q0Jv",
        "outputId": "c0b5727c-5eff-446c-bb54-03970c32830a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.74125236]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['it is recommended that you get tested for covid if flu-like symptoms occur'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol5auzae-_0O",
        "outputId": "07937358-6180-44a6-f16e-bcd1632e9384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.966005]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['i got vaccinated so it should be safe'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzyRVCUl_LyG",
        "outputId": "a2494be0-3e6e-4a36-e412-cb1e092cd1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4906899]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['beach ball'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgOW4yN9AMwn",
        "outputId": "fe0c896b-99e9-47b4-c9cb-9c641717a4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8127688]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['covid was created in a lab'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbcbLVhkAYSe",
        "outputId": "80baa44c-081d-462a-ec1d-ca4d34b7da40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99525416]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['covid'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfX6HykeAuJ1",
        "outputId": "2b55287d-f8d8-419b-8fc4-8c46442fe263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85981816]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['the vaccine is killing babies'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIKKXMkRDInW",
        "outputId": "49d04275-7612-40b4-c1a1-6843c1f5f9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4099576]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['i think covid will give you cancer but im not sure'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iIT-OOADP9N",
        "outputId": "44487acf-59b4-4c83-f29a-bc9f6a57ad42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4162552]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['yes covid will give you cancer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcuDG2RrDX1d",
        "outputId": "773befde-59d0-492e-9219-5a8b43a355e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5954191]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['the radical left is planning to decrease the older population with the vaccine'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PGAynszDerE",
        "outputId": "7bd5a312-45af-419f-a865-b648572a0a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5560514]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(['covid fake propaganda populist theory vaccine bad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhwcwiuQAgVG",
        "outputId": "8fbf2e89-b5d0-49ad-c89e-e7067433ca16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.34776455]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8le6lOgAlQp",
        "outputId": "2ad94777-ec0a-4e2b-a4bc-45be86f8c669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export_path = /tmp/1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l {export_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHjoFDR2BSIf",
        "outputId": "7d014203-5409-4587-eb89-cb01f743c648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 180\n",
            "drwxr-xr-x 2 root root   4096 Dec 26 05:59 assets\n",
            "-rw-r--r-- 1 root root  10744 Dec 26 05:59 keras_metadata.pb\n",
            "-rw-r--r-- 1 root root 159919 Dec 26 05:59 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Dec 26 05:59 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_cli show --dir {export_path} --all"
      ],
      "metadata": {
        "id": "1FkMC7eaBbwe",
        "outputId": "0ef6789e-d638-4268-e5d3-d6bf0df3f47a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-246909e59f03>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    saved_model_cli show --dir {export_path} --all\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        "    )"
      ],
      "metadata": {
        "id": "0z1wsJv9k5ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rZE2W4NoGqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77d22ea-316b-4683-e7c5-9df2302af360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f62640a6790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "modeLSTM.save('modeLSTM')\n",
        "#import tensorflowjs as tfjs\n",
        "\n",
        "#checkpoint_path = \"./checkpoints/cp-{epoch:05d}.ckpt\"\n",
        "#modeLSTM.save_weights(checkpoint_dir.format(epoch=0))\n",
        "#tfjs.converters.save_keras_model(model, '/content/drive/My Drive/archive (1)')\n",
        "#modeLSTM.save('/content/drive/My Drive/archive (1)', save_format = 'h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflowjs_converter --input_format keras \\ modelstuff/model.h5 \\ modelstuff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmUDr9Ku_YJb",
        "outputId": "e7d7deba-4efc-4c34-893c-8483cedf9008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorflowjs_converter` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "o1JPiSlp2CPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_input_features=784\n",
        "num_output_features=10\n",
        "\n",
        "\n",
        "class MLP(nn.module):\n",
        "  def __init__(self, num_input_features, num_output_features):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1=nn.Linear(num_input_features, 128)\n",
        "    self.fc2=nn.Linear(128,64)\n",
        "    self.fc3=nn.Linear(64, num_output_features)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    #no relu required bc it gives the final output\n",
        "    return x\n",
        "\n",
        "model = MLP(num_input_features, num_output_features)\n",
        "\n",
        "model.train()\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters,lr=0.01)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rB3obRs_NH9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYS2met5ddMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cbuzXTOmTbEkMaZzjxq4P2ll_lcKuw56",
      "authorship_tag": "ABX9TyOOOChXAwbsOo/Kbs1sQ1Aq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}